{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T20:48:01.247334Z",
     "start_time": "2024-10-01T20:48:01.230228Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "source": [
    "# https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/data?select=train.csv.zip"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T20:48:01.291197Z",
     "start_time": "2024-10-01T20:48:01.278644Z"
    }
   },
   "id": "5805ef1cb80f2b97",
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df['label'] = df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].max(axis=1)\n",
    "df = df.drop(['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'], axis=1)\n",
    "df = df.rename(columns={\"comment_text\": \"text\"})\n",
    "print(df.shape)\n",
    "display(df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T20:48:02.419875Z",
     "start_time": "2024-10-01T20:48:01.340773Z"
    }
   },
   "id": "e95194c7bc2fd6b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                text  label\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "source": [
    "df_0 = df[df['label'] == 0].sample(10000, random_state=42)\n",
    "df_1 = df[df['label'] == 1].sample(10000, random_state=42)\n",
    "df = pd.concat([df_0, df_1], axis=0)\n",
    "print(df[\"label\"].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T20:48:02.598009Z",
     "start_time": "2024-10-01T20:48:02.536041Z"
    }
   },
   "id": "c0117700bae7b7a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    10000\n",
      "1    10000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "source": [
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "print(train_data.shape, test_data.shape)\n",
    "\n",
    "# Use CountVectorizer to convert text to numerical features (bag-of-words)\n",
    "# This creates a vocabulary based on the training data and transforms the text into vectors\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")  # Limit vocabulary size to 5000 words\n",
    "X_train = vectorizer.fit_transform(train_data['text']).toarray()\n",
    "X_test = vectorizer.transform(test_data['text']).toarray()\n",
    "\n",
    "# Get labels for training and test sets\n",
    "y_train = train_data['label'].values\n",
    "y_test = test_data['label'].values\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T20:48:04.317081Z",
     "start_time": "2024-10-01T20:48:02.749174Z"
    }
   },
   "id": "93a1e8f03f272943",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 2) (4000, 2)\n",
      "(16000, 44099) (4000, 44099) (16000,) (4000,)\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T20:48:05.294062Z",
     "start_time": "2024-10-01T20:48:04.362670Z"
    }
   },
   "id": "361ff155e9e51ee6",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T20:48:05.380026Z",
     "start_time": "2024-10-01T20:48:05.318502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a custom dataset class to handle the input-output pairs\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, inputs, labels):\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.labels[idx]\n",
    "\n",
    "# Create training and testing datasets\n",
    "train_dataset = TextDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TextDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoader to iterate over data in batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ],
   "id": "15806fc01fcfdf5a",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T20:48:05.414076Z",
     "start_time": "2024-10-01T20:48:05.405270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple feed-forward neural network\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)  # First fully connected layer\n",
    "        self.relu = nn.ReLU()  # Activation function\n",
    "        self.fc2 = nn.Linear(128, 1)  # Output layer (binary classification)\n",
    "        self.sigmoid = nn.Sigmoid()  # Sigmoid for binary output\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)  # Apply first layer\n",
    "        x = self.relu(x)  # Apply ReLU activation\n",
    "        x = self.fc2(x)  # Apply second layer\n",
    "        x = self.sigmoid(x)  # Apply Sigmoid to get probabilities between 0 and 1\n",
    "        return x"
   ],
   "id": "e5395b74f8096e46",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T20:49:24.659174Z",
     "start_time": "2024-10-01T20:48:05.436807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set device (use GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = TextClassifier(input_dim=X_train.shape[1]).to(device)  # input_dim is the number of features (words in vocabulary)\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy loss for binary classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(preds)  # Round the predictions to 0 or 1\n",
    "    correct = (rounded_preds == y).float()  # Check how many predictions are correct\n",
    "    return correct.sum() / len(correct)  # Return accuracy\n",
    "\n",
    "# Training loop\n",
    "NUM_EPOCHS = 10  # Number of times to go over the entire training data\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()  # Set model to training mode\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    for (inputs, labels) in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "        predictions = model(inputs).squeeze(1)  # Get predictions from the model\n",
    "        \n",
    "        loss = criterion(predictions, labels)  # Calculate loss\n",
    "        acc = binary_accuracy(predictions, labels)  # Calculate accuracy\n",
    "        \n",
    "        loss.backward()  # Backpropagate to compute gradients\n",
    "        optimizer.step()  # Update model weights\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{NUM_EPOCHS} | Loss: {epoch_loss/len(train_loader):.4f} | Accuracy: {epoch_acc/len(train_loader):.4f}')\n"
   ],
   "id": "efc002a7b347b7d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Loss: 0.3982 | Accuracy: 0.8558\n",
      "Epoch 2/10 | Loss: 0.1347 | Accuracy: 0.9534\n",
      "Epoch 3/10 | Loss: 0.0556 | Accuracy: 0.9851\n",
      "Epoch 4/10 | Loss: 0.0270 | Accuracy: 0.9937\n",
      "Epoch 5/10 | Loss: 0.0148 | Accuracy: 0.9972\n",
      "Epoch 6/10 | Loss: 0.0088 | Accuracy: 0.9988\n",
      "Epoch 7/10 | Loss: 0.0060 | Accuracy: 0.9989\n",
      "Epoch 8/10 | Loss: 0.0042 | Accuracy: 0.9993\n",
      "Epoch 9/10 | Loss: 0.0038 | Accuracy: 0.9994\n",
      "Epoch 10/10 | Loss: 0.0028 | Accuracy: 0.9994\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T20:49:24.966802Z",
     "start_time": "2024-10-01T20:49:24.709707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "test_acc = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "    for (inputs, labels) in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        predictions = model(inputs).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, labels)  # Calculate loss\n",
    "        acc = binary_accuracy(predictions, labels)  # Calculate accuracy\n",
    "        \n",
    "        test_loss += loss.item()\n",
    "        test_acc += acc.item()\n",
    "\n",
    "print(f'Test Loss: {test_loss/len(test_loader):.4f} | Test Accuracy: {test_acc/len(test_loader):.4f}')\n"
   ],
   "id": "bd55f7aa377dd3ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5747 | Test Accuracy: 0.8630\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T20:51:13.999142Z",
     "start_time": "2024-10-01T20:51:13.985831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to classify a new text\n",
    "def predict_sentiment(model, text, vectorizer, device, threshold=0.5):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    # Transform text into numerical form using the trained vectorizer\n",
    "    vectorized_text = vectorizer.transform([text]).toarray()\n",
    "    \n",
    "    # Convert to tensor\n",
    "    tensor_text = torch.tensor(vectorized_text, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Get prediction\n",
    "    with torch.no_grad():\n",
    "        prediction = model(tensor_text).item()\n",
    "    \n",
    "    # Convert to binary class based on threshold\n",
    "    return \"Negative\" if prediction >= threshold else \"Positive\", prediction\n"
   ],
   "id": "74fcb30be2c0f918",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T20:51:52.304283Z",
     "start_time": "2024-10-01T20:51:52.289651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "new_text = \"I will eat a health meal!\"\n",
    "print(predict_sentiment(model, new_text, vectorizer, device))"
   ],
   "id": "41ea356378090121",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Positive', 0.005528016947209835)\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T20:49:25.081318Z",
     "start_time": "2024-10-01T20:49:25.074641Z"
    }
   },
   "cell_type": "code",
   "source": "print(device)",
   "id": "521191c3153a4650",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T20:49:25.115098Z",
     "start_time": "2024-10-01T20:49:25.110965Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e5a36288dbcef098",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
